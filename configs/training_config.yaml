model:
  type: "LogisticRegression"
  params:
    loss: "log_loss"
    penalty: "l2"
    alpha: 0.0001
    max_iter: 1000
    random_state: 42

training:
  batch_size: 512
  epochs: 10
  learning_rate: 0.001
  early_stopping_patience: 3
  validation_split: 0.2
  log_interval: 100

logging:
  batch_interval: 10
